---
title: "Support Vector Machine"
output: html_notebook
---


## Imports

```{r}
# Importing Function Packages
library(readr)
library(e1071)
library(Metrics)
library(dplyr)
library(ggplot2)

# Importing Data
house_pricing <- read_csv("house_pricing.csv")
```


## Aufteilung des Datensatzes in Trainings- und Validierungsdaten

```{r}
# Setting the random counter to a fixed value, so the random initialization stays the same (the random split is always the same)
set.seed(1)

# Assign each row number in the full dataset randomly to one of the three groups of datasets
# The probability of being in one of the groups results then in crresponding group sizes
assignment <- sample(1:2, size = nrow(house_pricing), prob = c(.9, .1), replace = TRUE)

# Create training and test datasets
train_dataset <- house_pricing[assignment == 1, ]  # subset house_pricing to training indices only
test_dataset <- house_pricing[assignment == 2, ]  # subset house_pricing to test indices only

```


## Data Preparation

```{r}
# Uncomment the next line if you want to check the correctness of your following code for the svm estimation with a small (and computationally fast) part of the training data set
train_dataset <- sample_frac(train_dataset, .10)
```


## Training the SVM

```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(price ~ bathrooms, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, price ~ bedrooms + bathrooms + sqft_living + zipcode, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```


## Checking the Prediction Quality


### Trainig Data

SVM with a standard hyperparameters
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(model_svm, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$price, pred_train)

```

SVM with hyperparameters tuned via grid search and cross validation
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$price, pred_train)
```

### Test Data

SVM with a standard hyperparameters
```{r}
# Calculating the prediction for the validation data using the best model according to the grid search
pred_test <- predict(model_svm, test_dataset)
# Calculating the prediction quality for the validation data using the MAPE
mape(test_dataset$price, pred_test)
```

SVM with hyperparameters tuned via grid search and cross validation
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$price, pred_test)
```

